[
  {
    "objectID": "worksheets/ws-01.html",
    "href": "worksheets/ws-01.html",
    "title": "Understanding the Challenge",
    "section": "",
    "text": "Designing a precipitation-monitoring network for a real forested catchment such as the Kellerwald is not a routine technical problem.\nIt is a multi-criteria design challenge that requires combining spatial reasoning, process understanding, and data-driven optimisation.\nBefore learning the analytical tools (e.g., Kriging, radar integration, hydrological modelling), you first need to understand what makes such a network “good” or “bad” — and why there is no single correct solution.",
    "crumbs": [
      "FAQ",
      "Worksheets",
      "Understanding the Challenge"
    ]
  },
  {
    "objectID": "worksheets/ws-01.html#background-and-problem-definition",
    "href": "worksheets/ws-01.html#background-and-problem-definition",
    "title": "Understanding the Challenge",
    "section": "Background and problem definition",
    "text": "Background and problem definition\nEstablishing a rain-gauge network in a complex forested upland such as the Kellerwald requires a clear understanding of how and why existing research catchments have organised their precipitation measurements. Gauge placement reflects climatic gradients, topographic controls, data uncertainty, and the need to link rainfall to hydrological response. To develop a robust concept for a new monitoring design, it is essential to study how benchmark field experiments have balanced spatial representativeness, measurement efficiency, and hydrological relevance.\n\nSelection and validation of reference sites\nThe five case studies were selected to represent well-documented hydrological observatories that combine long-term operation with explicit methodological transparency. Together they cover a broad spectrum of climatic regimes (arid to humid), land cover (semi-desert shrubland to temperate forest), and network-design philosophies (physiographic, statistical, and hydrological rationales). Each site provides publicly accessible metadata, peer-reviewed documentation, and a traceable evolution of its instrumentation, which allows the why and where of station deployment to be reconstructed rather than inferred.\nIn general, such selections are validated by three criteria:\n\nContinuity and data quality – multi-decadal, quality-controlled precipitation (and discharge) records are available.\n\nExplicit methodological reporting – publications or technical reports describe the logic or adjustment of station placement.\n\nScientific influence and reproducibility – the site serves as a benchmark or reference in later network-design or model-validation studies.\n\nThis combination reflects both the state of the art in network optimisation and the historical evolution of hydrological monitoring practice—from empirically grown catchments (Walnut Gulch, Reynolds Creek) to analytically optimised modern systems (HYREX, CAOS, Henriksen 2024).\n\n\n\n\n\n\nSelection and validation of reference sites\n\n\n\nPurpose\nProvide an explicit rationale for choosing benchmark catchments that reflect historical practice and current methodological standards in precipitation-network design.\nSelection logic\n- Long-term, quality-controlled hydro-meteorological data (&gt;10 years).\n- Explicit documentation of why and where gauges were deployed (peer-reviewed papers or technical reports).\n- Representativeness across climatic and physiographic settings (arid–humid, lowland–upland, forested–open).\n- Demonstrated influence in later modelling or network-optimisation studies.\nValidation\nCombine empirical heritage (Walnut Gulch, Reynolds Creek) with analytical optimisation (HYREX, CAOS, Henriksen 2024) to cover state-of-the-art and historical evolution.\n\n\n\n\n\n\n\n\nCommon pitfalls in selecting reference networks\n\n\n\nTypical mistakes\n- Using short-term campaigns (&lt; 2 years) without continuity or QC.\n- Choosing networks without metadata; if siting rationale or maintenance history cannot be reconstructed, comparisons lose value.\n- Relying on model-derived “virtual stations” instead of physical gauge networks.\n- Ignoring physiographic context (e.g., urban/agricultural networks as proxies for forested uplands).\n- Assuming modern equals better; some historical observatories remain superior due to documentation and consistency.\nReminder\nA benchmark network should be traceable, representative, and reproducible—not merely new or data-rich.",
    "crumbs": [
      "FAQ",
      "Worksheets",
      "Understanding the Challenge"
    ]
  },
  {
    "objectID": "worksheets/ws-01.html#reference-sites",
    "href": "worksheets/ws-01.html#reference-sites",
    "title": "Understanding the Challenge",
    "section": "Reference Sites",
    "text": "Reference Sites\nThe following table summarises five well-documented examples of mesoscale catchments (~200 km²) where the logic behind why, where, and how precipitation stations were deployed is explicitly or reconstructably described. These cases form the analytical reference for the conceptual network design for the Kellerwald. ::: {.table-responsive}\n\n\n\n\n\n\n\n\n\n\nExperiment / Basin (~Area)\nWhat the source provides (relevant to station deployment)\nCore network logic\nKey reference(s)\n\n\n\n\nWalnut Gulch Experimental Watershed (Arizona, USA ≈ 149 km²)\nLong-term precipitation and runoff monitoring network; documentation of network evolution since the 1950s, including motivation for high-density gauge placement in convective storm environments.\n~95 gauges; stations located to capture short-range variability of intense convective rainfall and to control ephemeral channel runoff at small drainage scales rather than using a uniform grid.\nGoodrich, D.C., et al. (2008): Long-term precipitation and runoff database, Walnut Gulch Experimental Watershed, Arizona, USA. Journal of Hydrometeorology, 9(2), 322–334.\n\n\nReynolds Creek Experimental Watershed (Idaho, USA ≈ 239 km²)\nHistorical development of the hydrometeorological network; explicit documentation of how stations were positioned along elevation and rain–snow transition gradients.\n“Climatological gradient design”: elevation-banded siting (valley / slope / ridge in each band); focus on orographic forcing, snow processes, wind exposure, and phase change of precipitation.\nSeyfried, M.S. & Flerchinger, G.N. (2011): Hydrology of the Reynolds Creek Experimental Watershed. Hydrological Processes, 25, 146–158. Hanson, C.L. (2001): Climate and Hydrology of the Reynolds Creek Experimental Watershed, Idaho. USDA-ARS Technical Report.\n\n\nAttert / CAOS catchments (Luxembourg ≈ 288 km²)\nProcess-oriented observatory; site selection described in terms of geology × land use × topographic position; rationale for clustered monitoring sites across “hydrotopes.”\n“Physiographic stratification” / “hydrotop representativeness”: at least one representative monitoring unit per combination of substrate, land cover, and landscape position; access and telemetry constraints are secondary.\nZehe, E., et al. (2014): HESS Opinions – From response units to functional units. Hydrology and Earth System Sciences, 18, 2433–2455. Loritz, R., et al. (2018): Picturing and modeling catchments by representative hillslopes. Hydrology and Earth System Sciences, 22, 4437–4457.\n\n\nHYREX – Brue Catchment (SW England ≈ 132 km²)\nDense operational rain-gauge network combined with weather radar; formal description of siting strategy and subsequent adaptive densification.\nTwo-stage optimisation: initial ≈ 5 km spacing, then targeted infill in zones of high radar–gauge mismatch and high kriging variance at 15-minute resolution.\nBrowning, K.A., et al. (1999): The HYREX Project: Hydrological Radar Experiment. Institute of Hydrology / NERC Design Report. Collier, C.G., et al. (2000): Accuracy of rainfall estimates by radar and raingauges for hydrological applications. Journal of Hydrology, 239, 1–25.\n\n\nHenriksen et al. 2024 (Denmark ≈ 180 km²)\nModern optimisation study using emulated rain fields and geostatistical criteria to quantify marginal information gain per additional gauge under budget constraints.\n“Information-gain optimisation”: ranking of candidate sites by expected reduction in interpolation uncertainty (e.g. kriging variance) with explicit cost–benefit analysis for network densification.\nHenriksen, H.J., et al. (2024): Emulator-based optimisation of rain-gauge networks at the mesoscale. Journal of Hydrology.\n\n\n\n\n:::",
    "crumbs": [
      "FAQ",
      "Worksheets",
      "Understanding the Challenge"
    ]
  },
  {
    "objectID": "worksheets/ws-01.html#hierarchy-of-deployment-rationales",
    "href": "worksheets/ws-01.html#hierarchy-of-deployment-rationales",
    "title": "Understanding the Challenge",
    "section": "Hierarchy of deployment rationales",
    "text": "Hierarchy of deployment rationales\nAcross the benchmark catchments in the table, deployment rationales follow a hierarchical, not equal, structure. At the upper structural level, physiographic stratification defines the spatial framework of the network. This principle is explicit in Reynolds Creek and Attert/CAOS, where gauges were distributed along dominant gradients of elevation, geology, and land cover to guarantee structural representativeness before any statistical optimisation.\nAt the intermediate analytical level, information-gain optimisation refines density and placement within those strata. This rationale is most evident in HYREX (Brue Catchment) and Henriksen et al. 2024, where new gauges were allocated according to the marginal reduction of kriging variance or radar–gauge residuals under explicit budget constraints. The network evolves adaptively, responding to measured or modelled uncertainty rather than to fixed geometry.\nAt the lowest functional level, hydrological coupling links the precipitation network to discharge response. This coupling guided Walnut Gulch, where each ephemeral drainage required at least one gauge to translate storm rainfall into local runoff volumes. Modern frameworks couple this validation loop with statistical optimisation: unsatisfactory P→Q coherence or water-balance residuals trigger iterative refinement of both gauge density and stratification boundaries.\nSummary of the hierarchy\n- Physiographic stratification — structural representativeness (Reynolds Creek, Attert/CAOS).\n- Information-gain optimisation — analytical efficiency (HYREX, Henriksen 2024).\n- Hydrological coupling — functional adequacy (Walnut Gulch).",
    "crumbs": [
      "FAQ",
      "Worksheets",
      "Understanding the Challenge"
    ]
  },
  {
    "objectID": "worksheets/ws-01.html#task-overview",
    "href": "worksheets/ws-01.html#task-overview",
    "title": "Understanding the Challenge",
    "section": "Task overview",
    "text": "Task overview\nWork in pairs. Objective: understand how precipitation stations are deployed in field hydrology and apply this logic to the Kellerwald region (~200 km²).\n\n1. Study the examples\nRead the table and the section on deployment rationales. Identify, for each case study, which principle dominates:\n\nPhysiographic stratification\n\nInformation-gain optimisation\n\nHydrological coupling\n\n\n\n\n\n\n\nYour notes\n\n\n\nSummarise which rationale dominates in each example and why it fits the environmental setting.\n\n\n\n\n2. Develop your own concept\nDesign a conceptual rain-gauge network for the Kellerwald. Decide where gauges should be placed and explain the reasoning using the three rationales as a framework.\n\n\n\n\n\n\nConcept sketch\n\n\n\nDescribe or visualise the proposed network layout (schematic or georeferenced). A hand-drawn sketch or simple diagram may be uploaded.\n\n\n\n\n3. Identify required datasets\nList the data and measurements needed to implement the design. Focus on primary environmental and technical inputs, not pre-interpreted map products.\nExamples\n- Digital elevation model (DEM) and derived slope/exposure\n- Land-cover and forest-structure data\n- Radar reflectivity or gauge-adjusted precipitation fields\n- Stream-gauge and discharge records\n- Infrastructure and accessibility (power, communication, roads)\n\n\n\n\n\n\nData requirements\n\n\n\nSeparate available datasets (existing sources) from missing/uncertain ones that would require acquisition.\n\n\nOutput\nPrepare a one-page concept note or mini-poster including: (1) conceptual network sketch, (2) key design rationale, (3) list of required datasets and measurement sources. Upload this as a PDF to the Ilias Folder Deliverables. Naming Convention: NAME1_NAME2_Task1.pdf",
    "crumbs": [
      "FAQ",
      "Worksheets",
      "Understanding the Challenge"
    ]
  },
  {
    "objectID": "worksheets/ws-01.html#help",
    "href": "worksheets/ws-01.html#help",
    "title": "Understanding the Challenge",
    "section": "Help",
    "text": "Help\n\n\n\n\n\n\nClassical literature search (from broad to benchmarked shortlist)\n\n\n\nA. Define scope & inclusion criteria (before searching)\n- Mesoscale (~100–300 km²) field catchments with dense rain-gauge networks.\n- Must have: multi-year QC’d P (and ideally Q), documented siting/deployment rationale, accessible metadata.\n- Ensure diversity: include at least one arid/semi-arid, one temperate upland/forested, and one radar-coupled design study.\n- Exclude: &lt; 2 years duration; purely model/virtual networks; no siting documentation.\nB. Seed the search (databases)\n- Web of Science / Scopus (structured), Google Scholar (recall), institutional repositories (USDA-ARS, NERC/NORA, national hydrological services).\n- Boolean examples:\n- (\"rain gauge\" OR pluviometer) AND (network OR deployment OR siting) AND (catchment OR watershed) AND (design OR optimisation OR \"kriging variance\" OR \"conditional entropy\")\n- Add scale: (\"experimental watershed\" OR observatory) AND (km2 OR \"km²\")\n- Add context: forest* OR orograph* OR upland, and for radar-coupled: radar AND gauge AND merging.\nC. Backward & forward snowballing\n- Backward: screen reference lists of key hits (observatories, radar–gauge reviews, optimisation papers).\n- Forward: “Cited by” / “Times cited” to find design/upgrade papers and technical reports.\n- For observatories: combine catchment name with \"technical report\" OR \"instrumentation plan\" OR \"site manual\".\nD. Screen & extract (mini-PRISMA mindset)\n- Maintain a log (query → results → screened → included; record exclusion reasons).\n- Extract into a table: Site | Area | Climate/Land cover | Gauge count & resolution | Deployment rationale (physiographic / info-gain / hydrological) | Docs/Links.\n- Validate with checklist: continuity ≥ 10 y; explicit siting rationale; scientific influence; data access.\nE. Stop rule\n- When each rationale has ≥ 1 high-quality case and ≥ 2 climatic/physiographic regimes are covered, freeze the shortlist and justify it with the checklist.\n\n\n\n\n\n\n\n\nOptimised ChatGPT prompt (template)\n\n\n\nUse the following prompt when an assistant is allowed to browse the web and compile benchmark observatories with explicit deployment rationale.\nTask: Identify 5–7 benchmark hydrological field catchments (~100–300 km²) with dense rain-gauge networks where the deployment rationale (why/where/how gauges were placed) is explicitly documented in peer-reviewed papers or technical reports.\nContext: We are designing a rain-gauge network for the Kellerwald (forested upland, Germany). We need reference sites that reflect both state-of-the-art optimisation and historically grown observatories.\nConstraints & preferences:\n\nPrioritize sources with explicit siting/deployment rationale (not just data).\nInclude at least one arid/semi-arid, one temperate upland/forested, and one radar–gauge optimisation study.\nPrefer open-access or repository-backed documents (USDA-ARS, NERC/NORA, national hydrological services).\nExclude short-term (&lt;2 years) campaigns and purely model/virtual networks.\n\nDeliverables:\n\nA concise table: Site | Area (km²) | Climate/Land cover | Gauge density & time resolution | Dominant rationale (physiographic / information-gain / hydrological) | Why this site qualifies | Open link(s) (PDF/DOI/repository)\n4–6 bullet “selection/validation” notes (continuity, documentation quality, influence, data access).\n3–5 search strings for Web of Science / Scopus / Scholar.\n\nImportant:\n\nUse web browsing to verify links (prefer PDF/DOI/repository).\nCite exact titles and years; avoid non-authoritative sources.\nIf the siting rationale is only in a technical report, include that report.\n\nNow begin. First list planned search queries, then produce the table and notes.\nRationale\nRole specification + constraints + explicit deliverables increase reproducibility and the proportion of authoritative sources returned.\n\n\n\nValidating the quality of AI-assisted literature results\nUsing large-language-model tools (e.g. ChatGPT) for academic research requires the same critical discipline as any other secondary data source.\nA response generated by such a model is not evidence; it is a hypothesis that must be verified.\nTo assess the validity and reliability of AI-generated content, apply the following multi-step check:\n\nTraceability — Every claim or citation must be verifiable through an identifiable, accessible primary source (DOI, repository, or technical report).\n\nIf the model provides a reference, check that the DOI or link resolves correctly.\n\nIf it does not, the information cannot be treated as valid data.\n\nCross-verification — Confirm that at least one independent, authoritative publication (peer-reviewed or institutional) supports the same information.\n\nUse Web of Science, Scopus, or Google Scholar to triangulate keywords or exact phrasing.\n\nContradictory evidence must be noted explicitly, not ignored.\n\nContext consistency — Ensure that the terminology and scope of the AI response align with the disciplinary context (hydrology, RS, GIS).\n\nOver-generalised or discipline-agnostic phrasing is a warning sign of low specificity.\n\nCompleteness and bias check — Evaluate whether the model omits critical perspectives (e.g. older but seminal field experiments, regional studies).\n\nIf the list looks too homogeneous or too recent, broaden the manual search.\n\nReproducibility test — Re-run the same prompt (or a slightly varied one) at a later time or with another model.\n\nStable, consistent core results indicate higher robustness; volatile or entirely different answers suggest low reliability.\n\n\nRule of thumb:\nAn AI-generated result is acceptable only when it is (a) traceable to verifiable sources, (b) internally consistent, and (c) replicable through manual or bibliographic methods.\nIf any of these conditions fail, the output must be treated as exploratory, not evidential.",
    "crumbs": [
      "FAQ",
      "Worksheets",
      "Understanding the Challenge"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Advanced GIS & RS",
    "section": "",
    "text": "Throughout this course you will learn how to design, analyse, and evaluate a spatially explicit hydrological monitoring network.\nYour overarching goal is to develop a reproducible and defensible rain-gauge network concept for the Kellerwald region (~200 km²).\nThis is not a purely technical mapping task, but a research-oriented design challenge that connects spatial reasoning, remote-sensing data, and hydrological process understanding.\nThe project evolves in three conceptual phases:\n\nExploration – Identify what makes a precipitation network “good” or “bad”, and define what “optimal” could mean in this context.\n\nDevelopment – Apply methods learned in class (Kriging, radar bias correction, RS integration, uncertainty analysis) to iteratively refine your network.\n\nSynthesis – Present and defend a transparent, reproducible network design that links rainfall monitoring to hydrological response at sub-catchment scale.\n\n\n\n\n\nAt the end of the course each group submits three complementary products:\n\n\nA public or shared repository (e.g. GitHub, GitLab, or institutional server) that contains: - All data sources, scripts, and documentation used to derive your final network.\n- A reproducible workflow that shows how you went from raw data to station selection and evaluation.\n- Clear version control and short README explaining structure and logic.\nThe repository represents the traceable backbone of your project and demonstrates reproducibility and collaboration.\n\n\n\nA concise visual summary of: - The final proposed network (map and rationale).\n- The main methodological steps (e.g. interpolation, uncertainty analysis).\n- Key results or validation indicators.\n- A short reflection on limitations and future improvement.\nThe poster must communicate the project as if presented at a professional hydrology or GIS conference.\n\n\n\nEach group presents their poster in a short oral pitch (max 5 min).\nThe goal is to argue convincingly why your design is optimal for its chosen criteria (coverage, efficiency, hydrological adequacy).\nThe pitch should demonstrate technical understanding, critical reasoning, and teamwork.\n\n\n\n\n\nEach submission is evaluated across five dimensions, 0–2 points each (max 10 pts):\n\n\n\n\n\n\n\n\n\nCriterion\n0\n1\n2\n\n\n\n\nSpatial reasoning\narbitrary placement\npartial coverage of key gradients\nsystematic physiographic logic (Luv–Lee, elevation, forest density)\n\n\nHydrological integration\nno link to runoff\nimplicit link to subcatchments\nexplicit precipitation–discharge coupling and closure logic\n\n\nMethodological rigour\nad-hoc reasoning\npartial quantitative justification\nreproducible workflow using kriging, RS, or uncertainty metrics\n\n\nTransparency & reproducibility\nno documentation\npartial scripts / missing metadata\ncomplete, documented, and reproducible repository\n\n\nCommunication quality\nunclear poster / pitch\npartially coherent argument\nclear, concise, and scientifically convincing presentation\n\n\n\n\n\n\n\nThe Kellerwald Network Design Project is structured as a friendly competition:\nthe group achieving the highest total score becomes the Course Design Champion.\nIn case of a tie, the tiebreaker is Hydrological integration, since the final goal is a coherent rainfall–runoff framework, not aesthetic map design.\n\n\n\n\nBy completing the full project you will be able to: - Formulate and test design hypotheses for spatial monitoring networks.\n- Apply geostatistical, RS, and modelling tools to evaluate network performance.\n- Document and communicate your workflow transparently.\n- Defend a reasoned, evidence-based concept of “optimality” in hydrological monitoring.\n:::"
  },
  {
    "objectID": "index.html#course-deliverable-kellerwald-network-design-project",
    "href": "index.html#course-deliverable-kellerwald-network-design-project",
    "title": "Advanced GIS & RS",
    "section": "",
    "text": "Throughout this course you will learn how to design, analyse, and evaluate a spatially explicit hydrological monitoring network.\nYour overarching goal is to develop a reproducible and defensible rain-gauge network concept for the Kellerwald region (~200 km²).\nThis is not a purely technical mapping task, but a research-oriented design challenge that connects spatial reasoning, remote-sensing data, and hydrological process understanding.\nThe project evolves in three conceptual phases:\n\nExploration – Identify what makes a precipitation network “good” or “bad”, and define what “optimal” could mean in this context.\n\nDevelopment – Apply methods learned in class (Kriging, radar bias correction, RS integration, uncertainty analysis) to iteratively refine your network.\n\nSynthesis – Present and defend a transparent, reproducible network design that links rainfall monitoring to hydrological response at sub-catchment scale.\n\n\n\n\n\nAt the end of the course each group submits three complementary products:\n\n\nA public or shared repository (e.g. GitHub, GitLab, or institutional server) that contains: - All data sources, scripts, and documentation used to derive your final network.\n- A reproducible workflow that shows how you went from raw data to station selection and evaluation.\n- Clear version control and short README explaining structure and logic.\nThe repository represents the traceable backbone of your project and demonstrates reproducibility and collaboration.\n\n\n\nA concise visual summary of: - The final proposed network (map and rationale).\n- The main methodological steps (e.g. interpolation, uncertainty analysis).\n- Key results or validation indicators.\n- A short reflection on limitations and future improvement.\nThe poster must communicate the project as if presented at a professional hydrology or GIS conference.\n\n\n\nEach group presents their poster in a short oral pitch (max 5 min).\nThe goal is to argue convincingly why your design is optimal for its chosen criteria (coverage, efficiency, hydrological adequacy).\nThe pitch should demonstrate technical understanding, critical reasoning, and teamwork.\n\n\n\n\n\nEach submission is evaluated across five dimensions, 0–2 points each (max 10 pts):\n\n\n\n\n\n\n\n\n\nCriterion\n0\n1\n2\n\n\n\n\nSpatial reasoning\narbitrary placement\npartial coverage of key gradients\nsystematic physiographic logic (Luv–Lee, elevation, forest density)\n\n\nHydrological integration\nno link to runoff\nimplicit link to subcatchments\nexplicit precipitation–discharge coupling and closure logic\n\n\nMethodological rigour\nad-hoc reasoning\npartial quantitative justification\nreproducible workflow using kriging, RS, or uncertainty metrics\n\n\nTransparency & reproducibility\nno documentation\npartial scripts / missing metadata\ncomplete, documented, and reproducible repository\n\n\nCommunication quality\nunclear poster / pitch\npartially coherent argument\nclear, concise, and scientifically convincing presentation\n\n\n\n\n\n\n\nThe Kellerwald Network Design Project is structured as a friendly competition:\nthe group achieving the highest total score becomes the Course Design Champion.\nIn case of a tie, the tiebreaker is Hydrological integration, since the final goal is a coherent rainfall–runoff framework, not aesthetic map design.\n\n\n\n\nBy completing the full project you will be able to: - Formulate and test design hypotheses for spatial monitoring networks.\n- Apply geostatistical, RS, and modelling tools to evaluate network performance.\n- Document and communicate your workflow transparently.\n- Defend a reasoned, evidence-based concept of “optimality” in hydrological monitoring.\n:::"
  }
]